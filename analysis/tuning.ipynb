{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Ray Tune hyperparameter tuning runs\n",
    "\n",
    "This notebook uses Ray Tune's built-in search visualisation tools to show you how well tuning is doing, which hyperparameters are important/unimportant, etc. I suggest pointing it to your running Ray Tune search & regularly running it to make sure that the search is making progress. You may need to periodically interrupt your search & restart with tighter hyperparameter search ranges if you find that some hyperparameters are consistently terrible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import glob\n",
    "import html\n",
    "import io\n",
    "import numbers\n",
    "import os\n",
    "\n",
    "import cloudpickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import seaborn as sns\n",
    "import skopt\n",
    "\n",
    "from IPython.display import display, Image, HTML\n",
    "from ray import tune\n",
    "from skopt.plots import plot_evaluations, plot_objective\n",
    "\n",
    "from il_representations.utils import load_sacred_pickle\n",
    "\n",
    "sns.set(context='notebook', style='darkgrid')\n",
    "\n",
    "# !pip uninstall -y scipy sckikit-learn\n",
    "# !pip install scikit-learn==0.24.1 'scipy>=1.6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables that you can configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory used by the running Ray Tune instance. Should contain a file named\n",
    "# experiment_state-<date>.json.\n",
    "# *THIS SHOULD BE THE ONLY THING YOU NEED TO CHANGE*\n",
    "# Example: RUNNING_RAY_TUNE_DIR = '../runs/chain_runs/53/grid_search/'\n",
    "RUNNING_RAY_TUNE_DIR = '/scratch/sam/il-representations-gcp-volume/cluster-data/cluster-2021-01-25-tuning-try1/chain_runs/2/grid_search/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading internal scikit-optimise experiment state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedConfig:\n",
    "    \"\"\"Dumb wrapper class used in pretrain_n_adapt to hide things from skopt.\n",
    "    It's in a separate module so that we can pickle it when pretrain_n_adapt is\n",
    "    __main__.\"\"\"\n",
    "    def __init__(self, config_dict):\n",
    "        self.config_dict = config_dict\n",
    "\n",
    "\n",
    "search_alg_pattern = os.path.join(RUNNING_RAY_TUNE_DIR, 'search-alg-*.pkl')\n",
    "pickle_paths = glob.glob(search_alg_pattern)\n",
    "if not pickle_paths:\n",
    "    raise IOError(\n",
    "        \"Could not find any matches for skopt state pattern, \"\n",
    "        f\"{search_alg_pattern!r}. Check whether skopt's .pkl file actually \"\n",
    "        f\"exists in RUNNING_RAY_TUNE_DIR={RUNNING_RAY_TUNE_DIR!r}.\")\n",
    "pickle_path, = pickle_paths\n",
    "with open(pickle_path, 'rb') as fp:\n",
    "    _, skopt_alg = load_sacred_pickle(fp)\n",
    "    \n",
    "skopt_res = skopt_alg.get_result()\n",
    "    \n",
    "# If variable names have not been saved and you have to add them back in, you can do something like this:\n",
    "# variable_names = ['foo', 'bar', 'baz', 'spam', 'ham', 'asdf']\n",
    "# for var_name, var in zip(variable_names, skopt_alg.space.dimensions):\n",
    "#     var.name = var_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring the task name\n",
    "\n",
    "We keep the \"base config\"—which is shared between all tuning runs—in a special skopt categorical variable in order to get around a Ray Tune bug. Helpfully, this lets us infer the benchmark and task name (assuming that those variables aren't also being optimised over by skopt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_by_name = {d.name: d for d in skopt_alg.space.dimensions}\n",
    "base_cfg_outer, = dims_by_name['+base_config'].categories\n",
    "base_cfg_inner = base_cfg_outer.config_dict\n",
    "env_cfg = base_cfg_inner['env_cfg']\n",
    "bench_name = env_cfg['benchmark_name']\n",
    "task_name = env_cfg['task_name']\n",
    "exp_ident = base_cfg_inner['il_test']['exp_ident']\n",
    "# magic spans are so that Google Docs doesn't mangle the bold :(\n",
    "display(HTML(f\"\"\"<p>\n",
    "<br/>\n",
    "<hr>\n",
    "<span style='font-weight: normal;'>Basic</span> config task/environment is <strong>{html.escape(bench_name)}</strong>/<strong>{html.escape(task_name)}</strong>.<br/>\n",
    "There are <strong>{len(skopt_alg.Xi)}</strong> completed runs in this hyperparameter tuning file.<br/>\n",
    "<code>exp_ident = <strong>{exp_ident}</strong></code><span style='font-weight: auto;'>.</span><br/><br/>\n",
    "</p>\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating hyperparameter sensitivity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_display_figure(figure=None):\n",
    "    \"\"\"Sometimes Jupyter refuses to show the most recently plotted figure.\n",
    "    This helper can _force_ it to display the figure.\n",
    "    \n",
    "    (unfortunately the Jupyter failure is sporadic, so we can't _always_\n",
    "    call this function or else we end up with double plots)\"\"\"\n",
    "    if figure is None:\n",
    "        figure = plt.gcf()\n",
    "    with io.BytesIO() as fp:\n",
    "        figure.savefig(fp)\n",
    "        fig_data = fp.getvalue()\n",
    "    display(Image(fig_data))\n",
    "\n",
    "# If we leave plot_dims out, then skopt tries to infer plot_dims itself.\n",
    "# Unfortunately skopt 0.8.1 has broken code for skipping over constant dimensions\n",
    "# (see the \"if space.dimensions[row].is_constant:\" branch in plot_evaluations---it\n",
    "# fails to update other arrays when it omits the constant dimension from plot_dims).\n",
    "# Thus we manually provide all plot_dims ourselves.\n",
    "_ = plot_evaluations(skopt_res, plot_dims=[d.name for d in skopt_res.space.dimensions])\n",
    "# force_display_figure()\n",
    "\n",
    "_ = plot_objective(skopt_res, n_samples=40, minimum='expected_minimum_random', n_minimum_search=1000)\n",
    "\n",
    "n_results = len(skopt_res.func_vals)\n",
    "fig = plt.figure()\n",
    "sns.distplot(skopt_res.func_vals, rug=True, norm_hist=False, kde=False, bins=10 if n_results >= 20 else None)\n",
    "plt.title(f\"Final loss distribution from {n_results} runs (lower = better)\")\n",
    "plt.xlabel(\"Final loss\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "# force_display_figure(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing the best encountered hyperparameter settings, ordered by loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we plot any config that has loss below 'thresh'\n",
    "# (by default, I've made it show the top 10 best configs;\n",
    "# you can change 'thresh' to anything you want)\n",
    "thresh = max(sorted(skopt_res.func_vals)[:20])\n",
    "good_inds, = np.nonzero(skopt_res.func_vals <= thresh)\n",
    "# for conf_num, good_ind in enumerate(good_inds, start=1):\n",
    "#     print(\n",
    "#         f\"Good config at index {good_ind} ({conf_num}/\"\n",
    "#         f\"{len(good_inds)}), thresh {thresh}:\")\n",
    "#     # TODO: print function value here too\n",
    "#     all_dims = skopt_res.space.dimensions\n",
    "#     for dim, value in zip(all_dims, skopt_res.x_iters[good_ind]):\n",
    "#         if dim.name == '+base_config':\n",
    "#             continue\n",
    "#         print(f'    {dim.name} = {value}')\n",
    "        \n",
    "print(f'Amalgamated \"good\" configs at thresh {thresh}:')\n",
    "for dim_idx, dimension in enumerate(skopt_res.space.dimensions):\n",
    "    if dimension.name == '+base_config':\n",
    "        continue\n",
    "    values = [skopt_res.x_iters[i][dim_idx] for i in good_inds]\n",
    "    if isinstance(values[0], float):\n",
    "        values_str = f\"[{', '.join('%.3g' % v for v in values)}]\"\n",
    "    else:\n",
    "        values_str = str(values)\n",
    "    if isinstance(values[0], (numbers.Number, bool)):\n",
    "        values_str += f' (mean: {np.mean(values)})'\n",
    "    print(f'    {dimension.name} = {values_str}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting skopt to guess which configurations are going to perform best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skopt_minima = []\n",
    "for i in range(10):\n",
    "    skopt_min = expected_minimum_random_sampling(\n",
    "        skopt_res, n_random_starts=1000000)\n",
    "    skopt_minima.append(skopt_min[0])\n",
    "print(\"skopt's guess at best configs (randomly sampled proposals):\")\n",
    "for idx, dim in enumerate(skopt_res.space.dimensions):\n",
    "    name = dim.name\n",
    "    values = [m[idx] for m in skopt_minima]\n",
    "    if isinstance(values[0], float):\n",
    "        stringified = [f'{v:.3g}' for v in values]\n",
    "    else:\n",
    "        stringified = map(str, values)\n",
    "    min_str = f'  {name} = [{\", \".join(stringified)}]'\n",
    "    print(min_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
