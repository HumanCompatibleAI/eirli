{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_dir = \"/home/cynthiachen/il-representations/runs/il_test_runs/8\"\n",
    "eval_files = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if 'eval' in f]\n",
    "eval_files.sort()\n",
    "\n",
    "with open(os.path.join(test_dir, 'config.json')) as f:\n",
    "    test_config = json.load(f)\n",
    "    \n",
    "benchmark_name = test_config['env_cfg']['task_name']\n",
    "policy_dir = test_config['policy_dir']\n",
    "exp_ident = \"no-augs\" if \"no\" in policy_dir else \"with-augs\"\n",
    "\n",
    "if policy_dir[-1] == '/':\n",
    "    policy_dir = os.path.dirname(policy_dir)\n",
    "\n",
    "train_config_file = os.path.join(os.path.dirname(policy_dir), 'config.json')\n",
    "\n",
    "with open(train_config_file) as f:\n",
    "    train_config = json.load(f)\n",
    "    \n",
    "train_exp_ident = train_config['exp_ident']\n",
    "if train_exp_ident == 'dmc-full-trajs-consistent-augs':\n",
    "    if train_config['bc']['n_trajs']:\n",
    "        train_exp_ident = f\"dmc-{train_config['bc']['n_trajs']}-trajs-consistent-augs\"\n",
    "\n",
    "print(train_exp_ident)\n",
    "print(test_config)\n",
    "print(benchmark_name)\n",
    "print(policy_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_dict(eval_files):\n",
    "    result_dict = {'n_update': []}\n",
    "\n",
    "    for eval_file in eval_files:\n",
    "        with open(eval_file) as f:\n",
    "            test_result = json.load(f)\n",
    "            \n",
    "        policy_name = test_result['policy_path'].split('/')[-1]\n",
    "        nupdate = int(policy_name.split('_')[-2])\n",
    "        if nupdate > 2000000:\n",
    "            continue\n",
    "        for key, value in test_result.items():\n",
    "            \n",
    "            # For procgen, we have different dicts for train_level and test_level results\n",
    "            if isinstance(value, dict) and 'return_mean' in value.keys():\n",
    "                return_mean = value['return_mean']\n",
    "                # Initialize list in result_dict if it hasn't been initialized\n",
    "                if key not in result_dict.keys():\n",
    "                    result_dict[key] = [return_mean]\n",
    "                else:\n",
    "                    result_dict[key].append(return_mean)\n",
    "\n",
    "        result_dict['n_update'].append(nupdate)\n",
    "    return result_dict\n",
    "\n",
    "result_dict = get_result_dict(eval_files)\n",
    "\n",
    "# The results might not be sorted according to nupdates, so we make sure\n",
    "# they are sorted correctly here.\n",
    "sorted_idx = sorted(range(len(result_dict['n_update'])), key=lambda k: result_dict['n_update'][k])\n",
    "for key, value in result_dict.items():\n",
    "    result_dict[key] = [result_dict[key][idx] for idx in sorted_idx]\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "ax = sns.lineplot(x='n_update', y='return_mean', data=mean_df)\n",
    "ax.set_title(f\"{benchmark_name}-{train_exp_ident}\")\n",
    "\n",
    "for key, value in result_dict.items():\n",
    "    if key != 'n_update':\n",
    "        ax = sns.lineplot(x='n_update', y=key, data=df, label=key)\n",
    "    ax.set_title(f\"{benchmark_name}-{exp_ident}\")\n",
    "    ax.set_ylabel(\"Return\")\n",
    "    sns.set(style='darkgrid')\n",
    "\n",
    "    fig = ax.get_figure()\n",
    "    fig.savefig(f\"{test_dir}/return_curve-{key}.png\")\n",
    "    \n",
    "    print(f\"Average number: {sum(value[1:])/len(value[1:])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "train_folder = Path(policy_dir).parent.absolute()\n",
    "progress_path = os.path.join(train_folder, 'progress.csv')\n",
    "progress_df = pd.read_csv(progress_path)\n",
    "\n",
    "ax = sns.lineplot(x='n_updates', y='loss', data=progress_df)\n",
    "ax.set_title(f\"{benchmark_name}-{train_exp_ident}\")\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(f\"{test_dir}/loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
