{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdvJgcG-qruR"
   },
   "source": [
    "# What are the geometric properties of datasets known to be amenable to repL?\n",
    "\n",
    "This file evaluates what the sort of embeddings that pretrained classifier networks learn. I'm particularly interested in whether classes cluster in the embedding space. I expect this to be the case for classifiers, but it would be particularly interesting if it were also the case for models trained using unsupervised learning, since that suggests there is some intrinsic relation between the geometry of samples from $p(x)$ and the label distribution $p(y \\mid x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eunecm1TFsGO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# some black magic from https://github.com/pytorch/pytorch/issues/30966#issuecomment-582747929\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ztx1JAnLKrG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# useful because it has pretrained SimCLR models\n",
    "# !pip install lightning-bolts[\"extra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "95O0yUfqqoqk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import models, datasets, transforms as T\n",
    "from torchvision.datasets.utils import download_url, download_and_extract_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zPL_5W0v4pX"
   },
   "source": [
    "## Downloading STL10\n",
    "\n",
    "We're going to try clustering part of the subset of STL10. STL10 is an ImageNet subset with images resized to 96x96. We upscale (naively) to the right size so we can feed the images into an actual ImageNet model; the STL10 default is 96$\\times$96, so the images will look a bit blurry if visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UEiHbM5q-Lr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MiniSTL10(datasets.STL10):\n",
    "    # STL10 with just the test set (1/10th the size)\n",
    "    url = 'https://www.qxcv.net/il/stl10_binary_test.tar.gz'\n",
    "    tgz_md5 = '1f2186acdb97f6a4a99f6ae43314f288'\n",
    "dataset = MiniSTL10('./data/stl10/', download=True, split='test', transform=T.Compose([\n",
    "    T.Resize(256), T.CenterCrop(224), T.ToTensor()\n",
    "]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "451WiXaL3biM"
   },
   "source": [
    "## Getting a pretrained ImageNet model\n",
    "\n",
    "We'll use this pretrained model to produce our embeddings. We want the output of the penultimate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3lIH91k3oJo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_pretrained = models.resnet18(pretrained=True, progress=True).eval().cuda()\n",
    "model_random = models.resnet18(pretrained=False).cuda()\n",
    "\n",
    "def resnet_get_avg_embedding(resnet, x):\n",
    "    # copied from https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py, but takes out\n",
    "    # the FC stuff at the end\n",
    "    assert isinstance(resnet, models.resnet.ResNet)\n",
    "    x = resnet.conv1(x)\n",
    "    x = resnet.bn1(x)\n",
    "    x = resnet.relu(x)\n",
    "    x = resnet.maxpool(x)\n",
    "\n",
    "    x = resnet.layer1(x)\n",
    "    x = resnet.layer2(x)\n",
    "    x = resnet.layer3(x)\n",
    "    x = resnet.layer4(x)\n",
    "\n",
    "    x = resnet.avgpool(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    # skip the FC layer (I think results are 2048-dimensional, which is a bit high; may have to random project down)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvjf470EKqkb"
   },
   "source": [
    "## Getting a pretrained SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0hKAx7bKs-p",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "\n",
    "# copied from https://pytorch-lightning-bolts.readthedocs.io/en/latest/self_supervised_models.html\n",
    "simclr_weight_path = 'https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt'\n",
    "simclr = SimCLR.load_from_checkpoint(simclr_weight_path, strict=False)\n",
    "simclr_resnet50 = simclr.encoder.cuda()\n",
    "simclr_resnet50.eval();  # semicolon to stop it printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9aqQ2AcPNds"
   },
   "source": [
    "## Downloading some MAGICAL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_2sM6fGhrld",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_and_extract_archive(\n",
    "    url='https://www.qxcv.net/il/magical-data-2021-05-18.tar.xz',\n",
    "    download_root='data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhRxSlT3iDX9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def make_imagenet_ds_magical():\n",
    "#     # use only latest frame\n",
    "#     obs_array = mag_data['obs'][:, -3:]\n",
    "#     # convert to [0,1]\n",
    "#     obs_tensor = torch.as_tensor(obs_array.astype('float32') / 255)\n",
    "#     # resize to 224*224\n",
    "#     obs_tensor = F.interpolate(obs_tensor, size=(224, 224), mode='bilinear', align_corners=False)\n",
    "#     # extract labels\n",
    "#     acts_tensor = torch.as_tensor(mag_data['acts'])\n",
    "#     tn_tensor = torch.as_tensor(mag_data['traj_num'])\n",
    "#     fn_tensor = torch.as_tensor(mag_data['frame_num'])\n",
    "#     return torch.utils.data.TensorDataset(obs_tensor, acts_tensor, tn_tensor, fn_tensor)\n",
    "#\n",
    "# magical_dl = torch.utils.data.DataLoader(make_imagenet_ds_magical(), batch_size=32, shuffle=True)\n",
    "\n",
    "def make_ilr_dl_magical(env_name_prefix, *, bs=32, shuffle=True):\n",
    "    \"\"\"Make a DataLoader for example data from the given environment (e.g. 'MoveToCorner' or 'MatchRegions').\"\"\"\n",
    "    matching_path, = glob.glob(f'data/magical-data-2021-05-18/mtr-extra-data/*{env_name_prefix}*.pt')\n",
    "    mag_data = torch.load(matching_path)\n",
    "    del mag_data['next_obs']\n",
    "    # use all frames\n",
    "    obs_array = mag_data['obs']\n",
    "    # convert to [0,1]\n",
    "    obs_tensor = torch.as_tensor(obs_array.astype('float32') / 255)\n",
    "    # extract labels\n",
    "    acts_tensor = torch.as_tensor(mag_data['acts'])\n",
    "    tn_tensor = torch.as_tensor(mag_data['traj_num'])\n",
    "    fn_tensor = torch.as_tensor(mag_data['frame_num'])\n",
    "    ds = torch.utils.data.TensorDataset(obs_tensor, acts_tensor, tn_tensor, fn_tensor)\n",
    "    return torch.utils.data.DataLoader(ds, batch_size=bs, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCGCMuGoSYiv"
   },
   "source": [
    "## Getting some pretrained MAGICAL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6pXe1VAgBHT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "magical_env_name_re = re.compile(r'MatchRegions|MoveToCorner|MoveToRegion|ClusterColour|ClusterShape|FindDupe|FixColour|MakeLine')\n",
    "remove_env_re = re.compile(f'_({magical_env_name_re.pattern})-[a-zA-Z]+-v[0-9]+')\n",
    "model_dir = 'data/magical-data-2021-05-18/traced_nets'\n",
    "model_files = [os.path.join(model_dir, p) for p in os.listdir(model_dir) if p.endswith('.pt')]\n",
    "magical_models_by_env = {}\n",
    "for model_file_path in model_files:\n",
    "    match = magical_env_name_re.search(model_file_path)\n",
    "    if match is not None:\n",
    "        match_str = match.group()\n",
    "    else:\n",
    "        print(f\"Could not find environment name for '{model_file_path}'\")\n",
    "        match_str = 'unk'\n",
    "    model = torch.jit.load(model_file_path, map_location=torch.device('cuda')).eval().cuda()\n",
    "    # identify model by basename but strip the .pt suffix\n",
    "    model_basename = os.path.basename(model_file_path)[:-3]\n",
    "    # also strip the env name\n",
    "    model_basename, _ = remove_env_re.subn('', model_basename)\n",
    "    magical_models_by_env.setdefault(match_str, []).append({'name': model_basename, 'model': model})\n",
    "\n",
    "print('Models by environment:')\n",
    "for e, l in magical_models_by_env.items():\n",
    "    print(f'{e}: {\", \".join(d[\"name\"] for d in l)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0Na64qa7pu8"
   },
   "source": [
    "## Computing some STL10 embeddings\n",
    "\n",
    "We're going to run a few STL10 images through our embedding function, then add them to a TensorBoard file that we can visualise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuiooZph7s1G",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# delete old runs before doing this\n",
    "!rm -r runs\n",
    "\n",
    "def save_embeddings_to_file(loader, compute_embeddings, run_name, env_name='magical', frame_width=48):\n",
    "    target_num_embeddings = 512\n",
    "    embeddings = []\n",
    "    imgs_32 = []\n",
    "    label_rows = None\n",
    "    label_names = None\n",
    "    print(f'Generating >={target_num_embeddings} embeddings')\n",
    "    for batch_in, *batch_labs in loader:\n",
    "        if len(batch_labs) == 1:\n",
    "            if label_rows is None:\n",
    "                label_rows = []\n",
    "                label_names = None\n",
    "            label_rows.extend(batch_labs[0].numpy())\n",
    "        else:\n",
    "            if env_name == 'magical':\n",
    "                if label_rows is None:\n",
    "                    label_rows = []\n",
    "                    label_names = ['acts', 'traj_num', 'frame_num', 'time_div10', 'time_div20', 'time_div30']\n",
    "                acts, traj_nums, frame_nums = batch_labs\n",
    "                for i in range(len(acts)):\n",
    "                    label_rows.append([\n",
    "                        acts[i], traj_nums[i], frame_nums[i], frame_nums[i] // 10, frame_nums[i] // 20, frame_nums[i] // 30\n",
    "                    ])\n",
    "            else:\n",
    "                if label_rows is None:\n",
    "                    label_rows = []\n",
    "                    label_names = ['acts', 'rews', 'trajs']\n",
    "                acts, rews, trajs = batch_labs\n",
    "                for i in range(len(acts)):\n",
    "                    label_rows.append([acts[i], rews[i], trajs[i]])\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = compute_embeddings(batch_in)\n",
    "            # resize each frame to 48x48, then lay out the frames in each stack horizontally\n",
    "            batch_in_resize = F.interpolate(batch_in, size=(frame_width, frame_width), mode='bilinear', \n",
    "                                            align_corners=False)\n",
    "            batch_in_resize = batch_in_resize.detach()\n",
    "            batch_in_stack = torch.reshape(batch_in_resize,\n",
    "                                           (batch_in_resize.shape[0], -1, 3,) + batch_in_resize.shape[2:])\n",
    "            batch_in_stack_t = torch.movedim(batch_in_stack, 1, 0)\n",
    "            double_resize = torch.reshape(\n",
    "                batch_in_stack_t,\n",
    "                (max(1, batch_in_stack_t.shape[0] // 2), -1) + batch_in_stack_t.shape[1:])\n",
    "            cat_h = torch.cat(list(double_resize), dim=4)\n",
    "            cat_v = torch.cat(list(cat_h), dim=2)\n",
    "            imgs_32.append(cat_v.detach().cpu())\n",
    "            \n",
    "        embeddings.append(batch_embeddings)\n",
    "        n_embed = sum(map(len, embeddings))\n",
    "        # Debug print, produces a lot of extra console output\n",
    "        # print(f'Have {n_embed} embeddings')\n",
    "        if n_embed >= target_num_embeddings:\n",
    "            break\n",
    "    embeddings = np.concatenate(embeddings, axis=0)\n",
    "    imgs_32 = torch.cat(imgs_32, dim=0)\n",
    "\n",
    "    # write to TB\n",
    "    writer = SummaryWriter(log_dir=f'runs/{run_name}', comment=run_name)\n",
    "    writer.add_embedding(\n",
    "        embeddings,\n",
    "        metadata=label_rows,\n",
    "        metadata_header=label_names,\n",
    "        tag=run_name,\n",
    "        # XXX label_img=imgs_32,\n",
    "    )\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "# magical_acts_dl, magical_fn_dl, magical_tn_dl\n",
    "# save_embeddings_to_file(\n",
    "#     magical_dl,\n",
    "#     lambda b: simclr_resnet50(b.cuda())[0].detach().cpu().numpy(),\n",
    "#     'magical_mtr_with_simclr_resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings_to_file(\n",
    "    dataloader,\n",
    "    lambda b: resnet_get_avg_embedding(model_pretrained, b.cuda()).detach().cpu().numpy(),\n",
    "    'stl10_with_pretrained_resnet18')\n",
    "save_embeddings_to_file(\n",
    "    dataloader,\n",
    "    lambda b: resnet_get_avg_embedding(model_random, b.cuda()).detach().cpu().numpy(),\n",
    "    'stl10_with_random_resnet18')\n",
    "save_embeddings_to_file(\n",
    "    dataloader,\n",
    "    lambda b: simclr_resnet50(b.cuda())[0].detach().cpu().numpy(),\n",
    "    'stl10_with_simclr_resnet50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MflZBKlzgM7m"
   },
   "source": [
    "## Computing some MAGICAL embeddings\n",
    "\n",
    "Going to repeat this for each dataset + model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsBWtebun8jX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for env_name_prefix, model_list in magical_models_by_env.items():\n",
    "    env_dl = make_ilr_dl_magical(env_name_prefix)\n",
    "    for model_dict in model_list:\n",
    "        name = model_dict['name']\n",
    "        model = model_dict['model'].cuda()\n",
    "        save_embeddings_to_file(\n",
    "            env_dl,\n",
    "            # lambda b: model(b.cuda()).detach().cpu().numpy(),\n",
    "            lambda b: model(b.cuda()).detach().cpu().numpy(),\n",
    "            env_name_prefix + '_' + name)\n",
    "    del env_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Procgen/DMC data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 512\n",
    "models_path = '/home/cynthiachen/il-representations/analysis/data/procgen'\n",
    "models_path = '/home/cynthiachen/il-representations/analysis/data/dmc'\n",
    "dmc_data_basepath = '/home/cynthiachen/il-representations/data/dm_control'\n",
    "procgen_data_basepath = '/scratch/cynthiachen/procgen_demo/'\n",
    "\n",
    "from il_representations.envs.utils import stack_obs_oldest_first\n",
    "from il_representations.envs.dm_control_envs import _load_pkl_gz_lists\n",
    "\n",
    "\n",
    "def make_ilr_dl_procgen(data_path, *, bs=32, shuffle=True):\n",
    "    \"\"\"Make a DataLoader for example data from the given environment.\n",
    "    \"\"\"\n",
    "    procgen_data = np.load(data_path, allow_pickle=True)\n",
    "    # Add trajectory label\n",
    "    traj_labels, tlabel = [], 0\n",
    "    for d in np.concatenate(procgen_data['dones'], axis=0)[:data_size]:\n",
    "        traj_labels.append(tlabel)\n",
    "        if d:\n",
    "            tlabel += 1\n",
    "    # Resize to [0, 1]\n",
    "    cat_obs = np.concatenate(procgen_data['obs'], axis=0)[:data_size]/255.\n",
    "    # Move channel to first dimension\n",
    "    cat_obs = np.transpose(cat_obs, (0, 3, 1, 2))\n",
    "    cat_obs = stack_obs_oldest_first(cat_obs, frame_stack=4, use_zeroed_frames=False)\n",
    "    acts_tensor = torch.tensor(np.concatenate(procgen_data['acts'], axis=0)[:data_size])\n",
    "    rews_tensor = torch.tensor(np.concatenate(procgen_data['rews'], axis=0)[:data_size]).int()\n",
    "    traj_tensor = torch.tensor(traj_labels)\n",
    "    obs_tensor = torch.FloatTensor(cat_obs)\n",
    "    ds = torch.utils.data.TensorDataset(obs_tensor, acts_tensor, rews_tensor, traj_tensor)\n",
    "    return torch.utils.data.DataLoader(ds, batch_size=bs, shuffle=shuffle)\n",
    "\n",
    "\n",
    "def make_ilr_dl_dmc(data_path, *, bs=32, shuffle=True):\n",
    "    \"\"\"Make a DataLoader for example data from the given environment.\n",
    "    \"\"\"\n",
    "    loaded_trajs = _load_pkl_gz_lists([data_path])\n",
    "    dones_lists = [np.array([False] * (len(t.acts) - 1) + [True], dtype='bool') for t in loaded_trajs][:data_size]\n",
    "    cat_obs = np.concatenate([stack_obs_oldest_first(t.obs[:-1], frame_stack=3, use_zeroed_frames=True)\n",
    "                              for t in loaded_trajs], axis=0)[:data_size]/255.\n",
    "    acts_tensor = torch.tensor(np.concatenate([t.acts for t in loaded_trajs], axis=0)[:data_size])\n",
    "    \n",
    "    rews_tensor = torch.tensor(np.concatenate([t.rews for t in loaded_trajs], axis=0)[:data_size]).int()\n",
    "    cat_dones = np.concatenate(dones_lists, axis=0)[:data_size]\n",
    "    \n",
    "    traj_labels, tlabel = [], 0\n",
    "    for d in cat_dones:\n",
    "        traj_labels.append(tlabel)\n",
    "        if d:\n",
    "            tlabel += 1\n",
    "    traj_tensor = torch.tensor(traj_labels)\n",
    "    obs_tensor = torch.FloatTensor(cat_obs)\n",
    "    ds = torch.utils.data.TensorDataset(obs_tensor, acts_tensor, rews_tensor, traj_tensor)\n",
    "    return torch.utils.data.DataLoader(ds, batch_size=bs, shuffle=shuffle)\n",
    "\n",
    "\n",
    "def get_models(model_dir):\n",
    "    model_files = [os.path.join(model_dir, p) for p in os.listdir(model_dir) if p.endswith('.ckpt')]\n",
    "    models_by_env = {}\n",
    "    for model_file_path in model_files:\n",
    "        model = torch.load(model_file_path, map_location=torch.device('cuda')).eval().cuda()\n",
    "        # identify model by basename but strip the .ckpt suffix\n",
    "        model_basename = os.path.basename(model_file_path)[:-5]\n",
    "        # also strip the env name\n",
    "        model_basename_parts = model_basename.split('-')\n",
    "        if len(model_basename_parts) == 3:  # dmc names\n",
    "            env_name, algo = '-'.join(model_basename_parts[:2]), model_basename_parts[2]\n",
    "        elif len(model_basename_parts) == 2:  # procgen\n",
    "            env_name, algo = model_basename_parts[0], model_basename_parts[1]\n",
    "        models_by_env.setdefault(env_name, []).append({'name': model_basename, 'model': model})\n",
    "    return models_by_env\n",
    "\n",
    "print('Models by environment:')\n",
    "models_by_env = get_models(models_path)\n",
    "for e, l in models_by_env.items():\n",
    "    print(f'{e}: {\", \".join(d[\"name\"] for d in l)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get representation encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for env_name, model_list in models_by_env.items():\n",
    "    # This can be made more robust, though currently it's an easy way to tell.\n",
    "    is_dmc = True if '-' in env_name else False\n",
    "    print(env_name)\n",
    "    if is_dmc:\n",
    "        data_path = glob.glob(f'{dmc_data_basepath}/{env_name}-*.pkl.gz')[0]\n",
    "        env_dl = make_ilr_dl_dmc(data_path=data_path)\n",
    "    else:\n",
    "        data_path = f'{procgen_data_basepath}/demo_{env_name}.pickle'\n",
    "        env_dl = make_ilr_dl_procgen(data_path=data_path)\n",
    "    for model_dict in model_list:\n",
    "        name = model_dict['name']\n",
    "        model = model_dict['model'].cuda()\n",
    "        save_embeddings_to_file(\n",
    "            env_dl,\n",
    "            lambda b: model(b.cuda(), traj_info=None).mean.detach().cpu().numpy(),\n",
    "            name,\n",
    "            env_name='procgen', \n",
    "            frame_width=64\n",
    "        )\n",
    "    del env_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpczJW0t3kkR"
   },
   "source": [
    "## Visualising it all in TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfQAKG9aqxaS",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5wm9mE3_CJs",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "geometric_properties_of_datasets_that_you_can_do_repl_on.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
